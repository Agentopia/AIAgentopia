{
  "name": "Data Analyzer Bot",
  "description": "Upload tabular data (CSV/Excel) for automated exploratory data analysis. Generates a local report with profiling, visualizations, and insights.",
  "long_description": "### Overview\nThe Data Analyzer Bot is an interactive Streamlit web application that empowers you to conduct comprehensive Exploratory Data Analysis (EDA) on your tabular data (CSV or Excel) with just a few clicks. Upload your file and instantly access a multi-tab interface designed for deep dives and quick insights.\n\n### How it Works\n1.  **Upload Data:** Simply upload your CSV or Excel file through the user-friendly interface.\n2.  **Explore Tabs:** Navigate through dedicated tabs for:\n    *   **Interactive Query:** Ask natural language questions about your data and get answers from a powerful LLM.\n    *   **Automated Analysis:** Instantly view key statistical tables, including missing value analysis, descriptive statistics, and categorical value counts.\n    *   **Visualizations:** Automatically generate essential plots like histograms, bar charts, and a correlation heatmap to visually understand your data.\n    *   **AI Summary:** Generate a high-level, AI-powered summary of the key findings and anomalies in your dataset.\n3.  **Download Report:** From the 'Report' tab, generate and download a custom, self-contained HTML report containing your chosen analyses and visualizations.\n\nThis bot runs entirely on your local machine, ensuring your data remains private. It's the perfect tool for anyone needing to quickly understand, visualize, and report on a dataset without writing any code.",
  "use_cases": [
    "Get a quick overview and initial understanding of a new dataset.",
    "Automate the initial steps of Exploratory Data Analysis (EDA).",
    "Identify potential data quality issues (e.g., missing values, outliers) early.",
    "Generate a local, shareable HTML report with key statistics and visualizations.",
    "Prepare for more in-depth analysis or machine learning model training by understanding data characteristics."
  ],
  "category": "Data Analysis & Research",
  "subcategory": "Exploratory Data Analysis",
  "agentType": "Autonomous",
  "agentScale": "Single-Agent",
  "developmentFrameworks": ["Python", "Streamlit", "Pandas", "Matplotlib", "Seaborn", "Openpyxl", "Jinja2", "OpenAI API", "Anthropic Claude"],
  "intendedAudience": ["Data Analysts", "Business Users", "Students", "Researchers"],
  "dataModalities": ["Tabular Data"],
  "integrationType": "Streamlit Web App",
  "features": [
    "Interactive multi-tab Streamlit web interface.",
    "Supports both CSV and Excel file uploads.",
    "Interactive natural language querying of the dataset via LLMs (OpenAI or Claude).",
    "Automated statistical analysis: missing values, descriptive stats, and categorical frequencies.",
    "Automated data visualizations: histograms, bar charts, and a correlation heatmap.",
    "AI-powered narrative summary of key findings and insights.",
    "Customizable, downloadable, self-contained HTML report of the entire analysis.",
    "Secure API key management using a local .env file."
  ],
  "roadmap_features": [
    "Advanced UI Configuration: Allow users to customize analysis parameters, visualizations, and report content.",
    "Interactive HTML Reports: Enhance reports with interactive charts and tables (e.g., using Plotly).",
    "Data Cleaning Suggestions: Provide suggestions for data cleaning and options for automated application.",
    "Expanded Data Source Support: Add support for more data formats (e.g., Parquet) and direct database connections.",
    "Improved Error Handling: Implement more robust error handling for API keys and LLM communication."
  ],
  "tags": ["eda", "analytics", "reporting", "data-visualization", "statistics", "csv", "excel", "llm", "data-profiling", "html-report"],
  "version": "1.0.0",
  "author": "Agentopia Core Team",
  "demoUrl": "http://localhost:8501",
  "deployment_status": "Production",
  "entry_point": "app/ai_data_analyst.py",
  "setup_instructions": "### Prerequisites:\n*   Python 3.8+ installed.\n*   Docker installed (for containerized execution).\n*   An OpenAI or Anthropic API key if using the LLM-powered summary feature.\n\n### Option 1: Running with Docker (Recommended for ease of use)\n1.  Ensure Docker is running on your machine.\n2.  Build the Docker image using the provided `Dockerfile` or pull a pre-built image (see `docker_pull_instructions`).\n3.  Run the Docker container using the `docker_run_instructions`.\n4.  Access the Streamlit web interface by opening your browser to `http://localhost:8501`.\n\n### Option 2: Running Locally with Python\n1.  Clone the agent's source code repository (if applicable, or download the agent files).\n2.  Navigate to the agent's root directory: `cd agents/data-analyzer-bot`.\n3.  Create and activate a Python virtual environment:\n    *   `python -m venv .venv`\n    *   Windows: `.venv\\Scripts\\activate`\n    *   macOS/Linux: `source .venv/bin/activate`\n4.  Install the required dependencies: `pip install -r requirements.txt`\n5.  **Create a local environment file for API keys:**\n    *   In the agent's root directory (`agents/data-analyzer-bot`), create a file named `.env`.\n    *   Add your API keys to the `.env` file as follows:\n      ```\n      OPENAI_API_KEY=\"your_openai_api_key_here\"\n      ANTHROPIC_API_KEY=\"your_anthropic_api_key_here\"\n      ```\n    *   The application will automatically load these keys at startup. The `.env` file is included in `.gitignore` and will not be committed to your repository.\n6.  Run the Streamlit application:\n    `streamlit run app/ai_data_analyst.py`\n7.  Access the web interface by opening the local URL provided by Streamlit in your browser (usually `http://localhost:8501`).",
  "requirements": [
    "phidata",
    "streamlit==1.41.1",
    "openai==1.58.1",
    "pandas",
    "numpy==1.26.4",
    "openpyxl",
    "anthropic",
    "python-dotenv",
    "matplotlib",
    "seaborn",
    "markdown"
  ],
  "docker_image_name": "agentopia/data-analyzer-bot:1.0.0",
  "docker_pull_instructions": "```bash\ndocker pull agentopia/data-analyzer-bot:1.0.0\n```",
  "docker_run_instructions": "### Easiest Way to Run (Recommended)\n\n1.  **Run the Docker command:**\n    *   Open your terminal and run the following command. Docker will automatically download the image if you don't have it locally.\n\n    ```bash\n    docker run -it --rm -p 8501:8501 agentopia/data-analyzer-bot:1.0.0\n    ```\n\n2.  **Access the Web Interface:**\n    *   Open your web browser and navigate to `http://localhost:8501`.\n    *   You can now upload your data files directly through the interface.\n    *   If you wish to use the AI features, you can paste your API keys into the fields in the sidebar.\n\n### Advanced: Mounting a Local Data Directory\n\nIf you prefer to have your local data files automatically available to the agent, you can mount a directory.\n\n1.  **Prepare your data directory:**\n    *   Place your data files (CSV, Excel) in a folder on your computer (e.g., `C:\\Users\\YourUser\\data`).\n\n2.  **Run the Docker command with a volume mount:**\n\n    ```bash\n    # Replace '/path/to/your/data_dir' with your actual folder path\n    docker run -it --rm -p 8501:8501 -v /path/to/your/data_dir:/app/data agentopia/data-analyzer-bot:1.0.0\n    ```\n\n    *Note for Windows users: Use a path format like `C:/Users/YourUser/data`.*\n\n3.  **(Optional) Using a `.env` file for API Keys:**\n    *   For convenience, you can create a `.env` file in the directory where you run the command and add your keys:\n      ```\n      OPENAI_API_KEY=\"your_key\"\n      ANTHROPIC_API_KEY=\"your_key\"\n      ```\n    *   Then, add `--env-file ./.env` to your `docker run` command.",
  "llm_dependency": {
    "type": "OpenAI or Anthropic Claude",
    "apiKeyEnvVar": "OPENAI_API_KEY or ANTHROPIC_API_KEY",
    "modelRecommendation": "gpt-4o-mini or claude-3-opus-20240229",
    "notes": "This agent can use either OpenAI or Anthropic Claude models for generating insights. You'll need to provide the appropriate API key as an environment variable depending on which LLM provider you choose in the web interface."
  },
  "privacy_considerations": "This agent runs entirely as a local Streamlit application, ensuring your data privacy and security.\n\n*   **Data Stays Local:** Your data files (CSV, Excel) are processed directly on your machine within the browser session and are never uploaded to any external server.\n*   **LLM Interaction:** When you use the 'Interactive Query' or 'AI Summary' features, the application sends only the necessary contextual data (like column names, statistics, or your specific query) to your chosen LLM provider (OpenAI or Anthropic). Your raw dataset is not transmitted.\n*   **Secure API Key Handling:** Your API keys are managed locally by you in a `.env` file and are used directly from the application to communicate with the LLM provider. They are not stored or logged by the agent.\n*   **Local Report Generation:** The downloadable HTML report is generated and saved directly on your machine.",

  "source_url": "https://github.com/Agentopia/AIAgentopia/tree/main/agents/data-analyzer-bot",
  "icon": "ðŸ“Š"
}
