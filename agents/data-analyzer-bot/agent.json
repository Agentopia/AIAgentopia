{
  "name": "Data Analyzer Bot",
  "description": "Upload tabular data (CSV/Excel) for automated exploratory data analysis. Generates a local report with profiling, visualizations, and insights.",
  "long_description": "### Overview\nThe Data Analyzer Bot helps you get a quick understanding of your tabular datasets (CSV or Excel files). Upload your data, and the bot will perform an automated Exploratory Data Analysis (EDA), saving all results locally. The output includes:\n\n*   **Data Profile:** Key statistics like row/column counts, data types, missing value analysis, descriptive statistics for numerical columns (mean, median, stddev, min/max), and frequency counts for categorical columns.\n*   **Automated Visualizations:** Common charts such as histograms for numerical distributions, bar charts for categorical frequencies, and a correlation heatmap for numerical features. These are saved as image files.\n*   **LLM-Powered Summary:** A natural language summary of the dataset's characteristics and 2-3 potentially interesting observations or anomalies, generated by an LLM.\n*   **Consolidated HTML Report:** An HTML file (`report.html`) is generated in your specified output directory, which you can open in any web browser to view all analyses and visualizations in one place.\n\nThis bot is designed for local execution to ensure your data remains private. It's perfect for data analysts needing a quick first look, business users wanting to understand data without coding, or anyone needing a rapid, standardized report on a dataset.\n\n### How it Works\n1.  The user provides a path to a local CSV or Excel file and an output directory.\n2.  The bot uses libraries like Pandas to load and analyze the data programmatically.\n3.  It generates statistical summaries and visualizations (e.g., using Matplotlib/Seaborn), saving charts as image files.\n4.  This structured information (statistics, chart data/descriptions) is then passed to an LLM (e.g., via OpenAI API) to generate human-readable summaries and insights, saved as text.\n5.  All results, including the summary, chart images, and a main `report.html`, are saved to the user's specified local output directory.",
  "use_cases": [
    "Get a quick overview and initial understanding of a new dataset.",
    "Automate the initial steps of Exploratory Data Analysis (EDA).",
    "Identify potential data quality issues (e.g., missing values, outliers) early.",
    "Generate a local, shareable HTML report with key statistics and visualizations.",
    "Prepare for more in-depth analysis or machine learning model training by understanding data characteristics."
  ],
  "category": "Data Analysis & Research",
  "subcategory": "Exploratory Data Analysis",
  "agentType": "Autonomous",
  "agentScale": "Single-Agent",
  "developmentFrameworks": ["Python", "Streamlit", "Pandas", "Matplotlib", "Seaborn", "Openpyxl", "Jinja2", "OpenAI API", "Anthropic Claude"],
  "intendedAudience": ["Data Analysts", "Business Users", "Students", "Researchers"],
  "dataModalities": ["Tabular Data"],
  "integrationType": "Streamlit Web App",
  "features": [
    "Supports CSV and Excel file inputs.",
    "Automated data profiling (dimensions, data types, missing values).",
    "Descriptive statistics for numerical and categorical columns.",
    "Generation of key visualizations (histograms, bar charts, correlation heatmap) saved as image files.",
    "LLM-generated natural language summary of data and insights.",
    "Generates a consolidated HTML report viewable in any web browser.",
    "All data processing and report generation occurs locally for privacy."
  ],
  "roadmap_features": [
    "Interactive chart customization within the HTML report (using JS libraries).",
    "Natural language querying of the dataset (CLI or simple web interface).",
    "Advanced statistical tests (e.g., t-tests, ANOVA) included in the report.",
    "Data cleaning suggestions and automated application options.",
    "Support for more data formats (e.g., Parquet, SQL databases).",
    "User-configurable analysis parameters via a config file or CLI arguments.",
    "Option to run as a local web service for a more interactive experience."
  ],
  "tags": ["eda", "analytics", "reporting", "data-visualization", "statistics", "csv", "excel", "llm", "data-profiling", "html-report"],
  "version": "0.1.0",
  "author": "Agentopia Core Team",
  "demoUrl": "http://localhost:8501",
  "deployment_status": "development",
  "entry_point": "app/ai_data_analyst.py",
  "setup_instructions": "### Prerequisites:\n*   Python 3.8+ installed.\n*   Docker installed (for containerized execution).\n*   An OpenAI or Anthropic API key if using the LLM-powered summary feature.\n\n### Option 1: Running with Docker (Recommended for ease of use)\n1.  Ensure Docker is running on your machine.\n2.  Build the Docker image using the provided `Dockerfile` or pull a pre-built image (see `docker_pull_instructions`).\n3.  Run the Docker container using the `docker_run_instructions`.\n4.  Access the Streamlit web interface by opening your browser to `http://localhost:8501`.\n\n### Option 2: Running Locally with Python\n1.  Clone the agent's source code repository (if applicable, or download the agent files).\n2.  Navigate to the agent's root directory: `cd agents/data-analyzer-bot`.\n3.  Create and activate a Python virtual environment:\n    *   `python -m venv .venv`\n    *   Windows: `.venv\\Scripts\\activate`\n    *   macOS/Linux: `source .venv/bin/activate`\n4.  Install the required dependencies: `pip install -r requirements.txt`\n5.  (Optional) If using LLM features, set your API key as an environment variable:\n    *   Windows (Command Prompt): `set ANTHROPIC_API_KEY=your_key_here`\n    *   Windows (PowerShell): `$env:ANTHROPIC_API_KEY=\"your_key_here\"`\n    *   macOS/Linux: `export ANTHROPIC_API_KEY=your_key_here`\n6.  Run the Streamlit application:\n    `streamlit run app/ai_data_analyst.py`\n7.  Access the web interface by opening the local URL provided by Streamlit in your browser (usually `http://localhost:8501`).",
  "requirements": [
    "phidata",
    "streamlit==1.41.1",
    "openai==1.58.1",
    "pandas",
    "numpy==1.26.4",
    "openpyxl",
    "anthropic"
  ],
  "docker_image_name": "agentopia/data-analyzer-bot:0.1.0",
  "docker_pull_instructions": "```bash\ndocker pull agentopia/data-analyzer-bot:0.1.0\n```",
  "docker_run_instructions": "### Running the Data Analyzer Bot with Docker:\n\n1.  **Prepare your data directory (optional):**\n    *   If you have data files to analyze, place them in a directory on your host machine (e.g., `/path/to/your/data_dir`).\n\n2.  **Set Environment Variables (if using LLM):**\n    *   `OPENAI_API_KEY`: Your OpenAI API key (if using OpenAI models).\n    *   `ANTHROPIC_API_KEY`: Your Anthropic API key (if using Claude models).\n\n3.  **Run the Docker command:**\n\n    ```bash\n    # With data directory mounted (optional)\n    docker run -it --rm \\\n      -p 8501:8501 \\\n      -v /path/to/your/data_dir:/app/data \\\n      -e OPENAI_API_KEY=\"your_openai_api_key_here\" \\\n      -e ANTHROPIC_API_KEY=\"your_anthropic_api_key_here\" \\\n      agentopia/data-analyzer-bot:0.1.0\n    ```\n\n    **Explanation:**\n    *   `-it --rm`: Runs the container interactively and removes it once it exits.\n    *   `-p 8501:8501`: Maps port 8501 from the container to port 8501 on your host machine for the Streamlit web interface.\n    *   `-v /path/to/your/data_dir:/app/data`: (Optional) Mounts a local directory with your data files into the container at `/app/data`.\n    *   `-e OPENAI_API_KEY=\"your_openai_api_key_here\"`: (Optional) Sets the OpenAI API key as an environment variable.\n    *   `-e ANTHROPIC_API_KEY=\"your_anthropic_api_key_here\"`: (Optional) Sets the Anthropic API key as an environment variable.\n    *   `agentopia/data-analyzer-bot:0.1.0`: The Docker image to run.\n\n4.  **Access the Web Interface:**\n    *   Open your web browser and navigate to `http://localhost:8501` to access the Data Analyzer Bot interface.\n    *   Use the web interface to upload files, select an LLM provider, and analyze your data.",
  "llm_dependency": {
    "type": "OpenAI or Anthropic Claude",
    "apiKeyEnvVar": "OPENAI_API_KEY or ANTHROPIC_API_KEY",
    "modelRecommendation": "gpt-4o-mini or claude-3-opus-20240229",
    "notes": "This agent can use either OpenAI or Anthropic Claude models for generating insights. You'll need to provide the appropriate API key as an environment variable depending on which LLM provider you choose in the web interface."
  },
  "privacy_considerations": "This agent is designed for local execution via Docker or direct Python scripting. When run locally:\n\n*   **Data Stays Local:** Your data files (CSV, Excel) are processed on your machine and are not uploaded to any external server by default.\n*   **LLM Interaction:** If LLM features are enabled (e.g., for summaries), only the necessary aggregated statistics or contextual information (not the raw dataset itself, unless explicitly designed to send snippets for analysis which would be documented) are sent to the LLM provider (e.g., OpenAI). You are responsible for understanding the privacy policy of the chosen LLM provider.\n*   **API Keys:** Your API keys (e.g., OpenAI API key) are managed by you as environment variables and are used directly from the local execution environment to communicate with the LLM provider.\n*   **Generated Reports are Local:** All generated reports, charts, and summaries are saved to your specified local output directory.\n\nAlways review the agent's specific implementation if you have concerns about data handling beyond this general guidance.",
  "source_url": "https://github.com/Agentopia/AIAgentopia/tree/main/agents/data-analyzer-bot",
  "icon": "ðŸ“Š"
}
